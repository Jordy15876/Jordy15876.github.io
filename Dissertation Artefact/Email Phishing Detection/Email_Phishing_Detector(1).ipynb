{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_3r6ZK3C1Hq",
        "outputId": "1475867b-9510-4b6d-e66e-ddc31baa4e3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "import pickle\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import unquote\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense, Input\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from xgboost import XGBClassifier, plot_importance\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FsurlD4EeTQ",
        "outputId": "2fdb8ad8-063f-484b-e9ab-4975365629f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# In this I was using googlcolab and found that it would be easier for me to get my csv files with the emails by keeping thm on google drive thus for this we have to mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Then I went on to define the paths to the datasets in my Google Drive folder\n",
        "base_path = \"/content/drive/My Drive/email_datasets\"\n",
        "\n",
        "paths = {\n",
        "    'CEAS_08': f\"{base_path}/CEAS_08.csv\",\n",
        "    'Enron': f\"{base_path}/Enron.csv\",\n",
        "    'Ling': f\"{base_path}/Ling.csv\",\n",
        "    'Nigerian_Fraud': f\"{base_path}/Nigerian_Fraud.csv\",\n",
        "    'phishing_email': f\"{base_path}/phishing_email.csv\",\n",
        "    'SpamAssasin': f\"{base_path}/SpamAssasin.csv\",\n",
        "    'TREC_05': f\"{base_path}/TREC_05.csv\",\n",
        "    'TREC_06': f\"{base_path}/TREC_06.csv\",\n",
        "    'TREC_07': f\"{base_path}/TREC_07.csv\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m50n7mv4MKqv",
        "outputId": "4bf041a9-c7a8-4569-99e6-6691eb75bc4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['text_combined', 'label']\n"
          ]
        }
      ],
      "source": [
        "phish_path = \"/content/drive/My Drive/email_datasets/phishing_email.csv\"\n",
        "phish_df = pd.read_csv(phish_path, nrows=3)\n",
        "print(phish_df.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_5JWSoKDPc_",
        "outputId": "235c6ac3-2fef-4210-ebf3-e410892d1688"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded CEAS_08: 39153 emails\n",
            "Loaded Enron: 31275 emails\n",
            "Loaded Ling: 2859 emails\n",
            "Loaded Nigerian_Fraud: 3332 emails\n",
            "Loaded phishing_email: 82486 emails\n",
            "Loaded SpamAssasin: 7863 emails\n",
            "Loaded TREC_05: 59015 emails\n",
            "Loaded TREC_06: 16439 emails\n",
            "Loaded TREC_07: 68221 emails\n",
            "Total combined emails: 310643\n",
            "After cleaning, emails: 290429\n",
            "üßπ Removed rare classes (<10 samples): 2014 rows dropped.\n",
            "\n",
            "üîç Unique label values BEFORE encoding:\n",
            "label\n",
            "0    75789\n",
            "1    74165\n",
            "0    72413\n",
            "1    66048\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3423929459.py:96: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  self.df_combined['label'] = self.df_combined['label'].astype(str).str.strip().replace({'0.0': 0, '1.0': 1, '0': 0, '1': 1})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÅ Label Encoding Mapping:\n",
            "0 ‚Üí 0\n",
            "1 ‚Üí 1\n",
            "\n",
            "‚úÖ Data preparation complete: 70/15/15 split with safe SMOTE and tokenization.\n",
            "\n",
            "‚úÖ All tables and charts saved to Google Drive: /content/drive/My Drive/email_datasets\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import re\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import unquote\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from collections import Counter\n",
        "\n",
        "class DataProcessor:\n",
        "    def __init__(self, paths, max_vocab=10000, max_seq_len=200):\n",
        "        self.paths = paths\n",
        "        self.max_vocab = max_vocab\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.tokenizer_nltk = TreebankWordTokenizer()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.text_tokenizer = Tokenizer(num_words=self.max_vocab)\n",
        "        self.df_combined = None\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        #This function will be responsible for cleaning and normalising all the email text.\n",
        "        # First, BeautifulSoup will be used to remove HTML tags.\n",
        "        if not isinstance(text, str):\n",
        "            return \"\"\n",
        "        text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "        #After this then it will decode any of the URL-encoded characters.\n",
        "        text = unquote(text)\n",
        "        text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text) #At this line, the punctuation and special characters are removed and everything will be converted to lowercase.\n",
        "        text = text.lower()\n",
        "        words = self.tokenizer_nltk.tokenize(text) # This line will then remoove common English stop words.\n",
        "        filtered_words = [w for w in words if w.isalpha() and w not in self.stop_words]\n",
        "        return ' '.join(filtered_words)\n",
        "\n",
        "    def _handle_special_cases(self, name, path):\n",
        "        if \"phishing_email\" in name:\n",
        "            df = pd.read_csv(path)\n",
        "            if 'text_combined' in df.columns and 'label' in df.columns:\n",
        "                df['body'] = df['text_combined']\n",
        "                df['subject'] = ''\n",
        "                df['text'] = df['subject'] + ' ' + df['body']\n",
        "                df = df[['text', 'label']]\n",
        "                return df\n",
        "        return None\n",
        "\n",
        "    def load_and_prepare_dataset(self, path, subject_col='subject', body_col='body', label_col='label', combine_subject_body=True):\n",
        "        name = os.path.basename(path).lower()\n",
        "        df_special = self._handle_special_cases(name, path)\n",
        "        if df_special is not None:\n",
        "            return df_special\n",
        "\n",
        "        try:\n",
        "            df = pd.read_csv(path, encoding='utf-8', engine='python', on_bad_lines='skip')\n",
        "        except Exception as e:\n",
        "            print(f\"\\u274c Failed to load {path}: {e}\")\n",
        "            return pd.DataFrame(columns=['text', 'label'])\n",
        "\n",
        "        if combine_subject_body and subject_col in df.columns and body_col in df.columns:\n",
        "            df['text'] = df[subject_col].fillna('') + ' ' + df[body_col].fillna('')\n",
        "        elif 'text_combined' in df.columns:\n",
        "            df['text'] = df['text_combined'].fillna('')\n",
        "        elif body_col in df.columns:\n",
        "            df['text'] = df[body_col].fillna('')\n",
        "        else:\n",
        "            raise ValueError(f\"Could not find subject/body/text_combined columns in {path}\")\n",
        "\n",
        "        df = df[['text', label_col]].rename(columns={label_col: 'label'})\n",
        "        return df\n",
        "\n",
        "    def process_all(self):\n",
        "        df_list = []\n",
        "        for name, path in self.paths.items():\n",
        "            df = self.load_and_prepare_dataset(path)\n",
        "            print(f\"Loaded {name}: {len(df)} emails\")\n",
        "            df_list.append(df)\n",
        "        self.df_combined = pd.concat(df_list, ignore_index=True)\n",
        "        print(f\"Total combined emails: {len(self.df_combined)}\")\n",
        "\n",
        "        self.df_combined['clean_text'] = self.df_combined['text'].apply(self.clean_text)\n",
        "        self.df_combined = self.df_combined[self.df_combined['clean_text'].str.strip() != '']\n",
        "        print(f\"After cleaning, emails: {len(self.df_combined)}\")\n",
        "\n",
        "        min_samples_per_class = 10\n",
        "        label_counts = self.df_combined['label'].value_counts()\n",
        "        valid_labels = label_counts[label_counts >= min_samples_per_class].index\n",
        "        initial_len = len(self.df_combined)\n",
        "        self.df_combined = self.df_combined[self.df_combined['label'].isin(valid_labels)]\n",
        "        print(f\"\\U0001f9f9 Removed rare classes (<{min_samples_per_class} samples): {initial_len - len(self.df_combined)} rows dropped.\")\n",
        "\n",
        "        print(\"\\n\\U0001f50d Unique label values BEFORE encoding:\")\n",
        "        print(self.df_combined['label'].value_counts())\n",
        "\n",
        "        self.df_combined = self.df_combined.dropna(subset=['label'])\n",
        "        self.df_combined['label'] = self.df_combined['label'].astype(str).str.strip().replace({'0.0': 0, '1.0': 1, '0': 0, '1': 1})\n",
        "        self.df_combined['label'] = pd.to_numeric(self.df_combined['label'], errors='coerce')\n",
        "        self.df_combined = self.df_combined[self.df_combined['label'].isin([0, 1])].copy()\n",
        "        self.df_combined['label'] = self.df_combined['label'].astype(int)\n",
        "\n",
        "        self.le = LabelEncoder()\n",
        "        self.df_combined['label'] = self.le.fit_transform(self.df_combined['label'])\n",
        "\n",
        "        print(\"\\n\\U0001f501 Label Encoding Mapping:\")\n",
        "        for i, class_label in enumerate(self.le.classes_):\n",
        "            print(f\"{i} ‚Üí {class_label}\")\n",
        "\n",
        "# 70/15/15 Split + Tokenization + SMOTE\n",
        "# Initialize processor\n",
        "processor = DataProcessor(paths)\n",
        "processor.process_all()\n",
        "\n",
        "# Get cleaned data\n",
        "df_cleaned = processor.df_combined.copy()\n",
        "X_raw = df_cleaned['clean_text'].values\n",
        "y_raw = df_cleaned['label'].values\n",
        "\n",
        "# 70/15/15 split\n",
        "X_temp, X_test_text, y_temp, y_test = train_test_split(X_raw, y_raw, test_size=0.15, random_state=42)\n",
        "X_train_text, X_val_text, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1765, random_state=42)\n",
        "\n",
        "# Tokenizer ‚Äî This will go only on the training\n",
        "tokenizer = Tokenizer(num_words=processor.max_vocab)\n",
        "tokenizer.fit_on_texts(X_train_text)\n",
        "\n",
        "# Convert to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train_text)\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_val_text)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test_text)\n",
        "\n",
        "# Pad sequences\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=processor.max_seq_len, padding='post')\n",
        "X_val_pad = pad_sequences(X_val_seq, maxlen=processor.max_seq_len, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=processor.max_seq_len, padding='post')\n",
        "\n",
        "# Smote is only applied to the training\n",
        "smote = BorderlineSMOTE()\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train_pad, y_train)\n",
        "\n",
        "# Save datasets\n",
        "save_dir = \"/content/drive/My Drive/email_datasets\"\n",
        "with open(f\"{save_dir}/X_train_smote.pkl\", 'wb') as f:\n",
        "    pickle.dump(X_train_smote, f)\n",
        "with open(f\"{save_dir}/y_train_smote.pkl\", 'wb') as f:\n",
        "    pickle.dump(y_train_smote, f)\n",
        "with open(f\"{save_dir}/X_val_pad.pkl\", 'wb') as f:\n",
        "    pickle.dump(X_val_pad, f)\n",
        "with open(f\"{save_dir}/y_val.pkl\", 'wb') as f:\n",
        "    pickle.dump(y_val, f)\n",
        "with open(f\"{save_dir}/X_test_pad.pkl\", 'wb') as f:\n",
        "    pickle.dump(X_test_pad, f)\n",
        "with open(f\"{save_dir}/y_test.pkl\", 'wb') as f:\n",
        "    pickle.dump(y_test, f)\n",
        "with open(f\"{save_dir}/tokenizer.pkl\", 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "print(\"\\n‚úÖ Data preparation complete: 70/15/15 split with safe SMOTE and tokenization.\")\n",
        "\n",
        "\n",
        "def counts_to_df(counter, name):\n",
        "    df = pd.DataFrame.from_dict(counter, orient='index', columns=[name])\n",
        "    df.index.name = 'label'\n",
        "    return df.sort_index().reset_index()\n",
        "\n",
        "overall_counts = Counter(df_cleaned['label'])\n",
        "pre_smote_counts = Counter(y_train)\n",
        "post_smote_counts = Counter(y_train_smote)\n",
        "\n",
        "df_overall = counts_to_df(overall_counts, 'count_overall')\n",
        "df_overall['percent_overall'] = (df_overall['count_overall'] / df_overall['count_overall'].sum() * 100).round(2)\n",
        "\n",
        "df_pre = counts_to_df(pre_smote_counts, 'count_pre_smote_train')\n",
        "df_pre['percent_pre'] = (df_pre['count_pre_smote_train'] / df_pre['count_pre_smote_train'].sum() * 100).round(2)\n",
        "\n",
        "df_post = counts_to_df(post_smote_counts, 'count_post_smote_train')\n",
        "df_post['percent_post'] = (df_post['count_post_smote_train'] / df_post['count_post_smote_train'].sum() * 100).round(2)\n",
        "\n",
        "df_compare = df_overall.merge(df_pre, on='label').merge(df_post, on='label')\n",
        "\n",
        "# Save CSVs\n",
        "df_overall.to_csv(f\"{save_dir}/class_counts_overall.csv\", index=False)\n",
        "df_pre.to_csv(f\"{save_dir}/class_counts_train_pre_smote.csv\", index=False)\n",
        "df_post.to_csv(f\"{save_dir}/class_counts_train_post_smote.csv\", index=False)\n",
        "df_compare.to_csv(f\"{save_dir}/class_counts_compare.csv\", index=False)\n",
        "\n",
        "# Charts\n",
        "labels = sorted(set(pre_smote_counts.keys()) | set(post_smote_counts.keys()))\n",
        "x = np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "# Pre vs Post SMOTE\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.bar(x - width/2, [pre_smote_counts.get(l, 0) for l in labels], width, label='Pre-SMOTE')\n",
        "plt.bar(x + width/2, [post_smote_counts.get(l, 0) for l in labels], width, label='Post-SMOTE')\n",
        "plt.xticks(x, labels)\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('Label')\n",
        "plt.title('Class Balance: Train Pre- vs Post-SMOTE')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{save_dir}/class_balance_train_pre_vs_post_smote.png\", dpi=200)\n",
        "plt.close()\n",
        "\n",
        "# Overall\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.bar(labels, [overall_counts.get(l, 0) for l in labels])\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('Label')\n",
        "plt.title('Overall Dataset Distribution (Pre-SMOTE)')\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{save_dir}/class_balance_overall.png\", dpi=200)\n",
        "plt.close()\n",
        "\n",
        "# Per-source (optional)\n",
        "if 'source' in df_cleaned.columns:\n",
        "    df_source = df_cleaned.groupby(['source','label']).size().unstack(fill_value=0)\n",
        "    df_source.to_csv(f\"{save_dir}/per_source_class_counts_overall.csv\")\n",
        "    plt.figure(figsize=(10,6))\n",
        "    bottom = np.zeros(len(df_source))\n",
        "    for lab in sorted(df_source.columns):\n",
        "        vals = df_source[lab].values\n",
        "        plt.bar(df_source.index, vals, bottom=bottom, label=f\"Label {lab}\")\n",
        "        bottom += vals\n",
        "    plt.xticks(rotation=30, ha='right')\n",
        "    plt.ylabel('Count')\n",
        "    plt.xlabel('Source')\n",
        "    plt.title('Per-Source Class Distribution (Pre-SMOTE)')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{save_dir}/per_source_class_distribution_overall.png\", dpi=220)\n",
        "    plt.close()\n",
        "\n",
        "print(\"\\n‚úÖ All tables and charts saved to Google Drive:\", save_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKvIqXoXSKFg"
      },
      "outputs": [],
      "source": [
        "tk = processor.text_tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgpE7AapyYs5",
        "outputId": "b1c0f773-8b14-430a-a5c6-9386b7a1dfe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m3241/3241\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m691s\u001b[0m 211ms/step - accuracy: 0.9321 - loss: 0.1604 - val_accuracy: 0.9811 - val_loss: 0.0537\n",
            "Epoch 2/5\n",
            "\u001b[1m3241/3241\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m749s\u001b[0m 213ms/step - accuracy: 0.9840 - loss: 0.0477 - val_accuracy: 0.9790 - val_loss: 0.0584\n",
            "Epoch 3/5\n",
            "\u001b[1m3241/3241\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m739s\u001b[0m 212ms/step - accuracy: 0.9902 - loss: 0.0291 - val_accuracy: 0.9840 - val_loss: 0.0536\n",
            "Epoch 4/5\n",
            "\u001b[1m3241/3241\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m742s\u001b[0m 212ms/step - accuracy: 0.9942 - loss: 0.0176 - val_accuracy: 0.9837 - val_loss: 0.0584\n",
            "Epoch 5/5\n",
            "\u001b[1m3241/3241\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m684s\u001b[0m 211ms/step - accuracy: 0.9962 - loss: 0.0125 - val_accuracy: 0.9842 - val_loss: 0.0580\n",
            "\u001b[1m6482/6482\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 36ms/step\n",
            "\u001b[1m1352/1352\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 35ms/step\n",
            "‚úÖ Accuracy: 0.9852761019809074\n",
            "üéØ Precision: 0.9853078299956078\n",
            "üéØ Recall: 0.9852761019809074\n",
            "üéØ F1 Score: 0.9852776269516199\n",
            "\n",
            "üìã Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99     22301\n",
            "           1       0.98      0.99      0.98     20962\n",
            "\n",
            "    accuracy                           0.99     43263\n",
            "   macro avg       0.99      0.99      0.99     43263\n",
            "weighted avg       0.99      0.99      0.99     43263\n",
            "\n",
            "\n",
            "üßÆ Confusion Matrix:\n",
            " [[21900   401]\n",
            " [  236 20726]]\n",
            "‚úÖ Accuracy plot saved: /content/drive/My Drive/email_datasets/training_accuracy.png\n",
            "‚úÖ Loss plot saved: /content/drive/My Drive/email_datasets/training_loss.png\n",
            "‚úÖ Confusion matrix saved: /content/drive/My Drive/email_datasets/confusion_matrix_named.png\n",
            "‚úÖ Classification report saved: /content/drive/My Drive/email_datasets/classification_report.csv\n",
            "‚úÖ Feature importance plot saved: /content/drive/My Drive/email_datasets/xgb_feature_importance.png\n",
            "üì¶ Added to ZIP: lstm_checkpoint.keras\n",
            "üì¶ Added to ZIP: lstm_final_model.keras\n",
            "üì¶ Added to ZIP: lstm_xgb_model.pkl\n",
            "üì¶ Added to ZIP: text_tokenizer.pkl\n",
            "üì¶ Added to ZIP: xgb_predictions.csv\n",
            "üì¶ Added to ZIP: lstm_training_log.csv\n",
            "üì¶ Added to ZIP: training_accuracy.png\n",
            "üì¶ Added to ZIP: training_loss.png\n",
            "üì¶ Added to ZIP: confusion_matrix_named.png\n",
            "üì¶ Added to ZIP: xgb_feature_importance.png\n",
            "üì¶ Added to ZIP: classification_report.csv\n",
            "‚ùå Missing file (not zipped): label_encoder.pkl\n",
            "\n",
            "‚úÖ All artifacts zipped to: /content/drive/My Drive/email_datasets/hybrid_model_export.zip\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# üì¶ Imports\n",
        "import os, pickle, zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        ")\n",
        "from xgboost import XGBClassifier, plot_importance\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "\n",
        "# Load saved datasets\n",
        "base_path = \"/content/drive/My Drive/email_datasets\"\n",
        "with open(f\"{base_path}/X_train_smote.pkl\", 'rb') as f:\n",
        "    X_train = pickle.load(f)\n",
        "with open(f\"{base_path}/y_train_smote.pkl\", 'rb') as f:\n",
        "    y_train = pickle.load(f)\n",
        "with open(f\"{base_path}/X_val_pad.pkl\", 'rb') as f:\n",
        "    X_val = pickle.load(f)\n",
        "with open(f\"{base_path}/y_val.pkl\", 'rb') as f:\n",
        "    y_val = pickle.load(f)\n",
        "with open(f\"{base_path}/X_test_pad.pkl\", 'rb') as f:\n",
        "    X_test = pickle.load(f)\n",
        "with open(f\"{base_path}/y_test.pkl\", 'rb') as f:\n",
        "    y_test = pickle.load(f)\n",
        "with open(f\"{base_path}/tokenizer.pkl\", 'rb') as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "\n",
        "# Params\n",
        "embedding_dim = 64\n",
        "sequence_length = X_train.shape[1]\n",
        "vocab_size = 10001\n",
        "batch_size = 64\n",
        "total_epochs = 5\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# Build LSTM Model\n",
        "def build_model():\n",
        "    inp = Input(shape=(sequence_length,))\n",
        "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(inp)\n",
        "    x = Bidirectional(LSTM(units=48))(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    features = Dense(32, activation='relu', name='lstm_features')(x)\n",
        "    out = Dense(num_classes, activation='softmax')(features)\n",
        "    model = Model(inputs=inp, outputs=out)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train Model\n",
        "model = build_model()\n",
        "\n",
        "#  Paths\n",
        "checkpoint_path = f\"{base_path}/lstm_checkpoint.keras\"\n",
        "csv_log_path = f\"{base_path}/lstm_training_log.csv\"\n",
        "lstm_final_path = f\"{base_path}/lstm_final_model.keras\"\n",
        "xgb_model_path = f\"{base_path}/lstm_xgb_model.pkl\"\n",
        "tokenizer_path = f\"{base_path}/text_tokenizer.pkl\"\n",
        "xgb_pred_path = f\"{base_path}/xgb_predictions.csv\"\n",
        "plot_acc_path = f\"{base_path}/training_accuracy.png\"\n",
        "plot_loss_path = f\"{base_path}/training_loss.png\"\n",
        "conf_matrix_path = f\"{base_path}/confusion_matrix_named.png\"\n",
        "feature_importance_path = f\"{base_path}/xgb_feature_importance.png\"\n",
        "report_csv_path = f\"{base_path}/classification_report.csv\"\n",
        "zip_path = f\"{base_path}/hybrid_model_export.zip\"\n",
        "\n",
        "# Callbacks\n",
        "for path in [checkpoint_path, csv_log_path, lstm_final_path]:\n",
        "    if os.path.exists(path):\n",
        "        os.remove(path)\n",
        "\n",
        "checkpoint_cb = ModelCheckpoint(checkpoint_path, save_best_only=False)\n",
        "csv_logger = CSVLogger(csv_log_path, append=False)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=total_epochs,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=[checkpoint_cb, csv_logger]\n",
        ")\n",
        "\n",
        "# Extract Features\n",
        "feature_model = Model(inputs=model.input, outputs=model.get_layer('lstm_features').output)\n",
        "features_train = feature_model.predict(X_train)\n",
        "features_test = feature_model.predict(X_test)\n",
        "\n",
        "# Train XGBoost\n",
        "xgb = XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=num_classes,\n",
        "    learning_rate=0.2,\n",
        "    max_depth=8,\n",
        "    n_estimators=250,\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42\n",
        ")\n",
        "xgb.fit(features_train, y_train)\n",
        "y_pred = xgb.predict(features_test)\n",
        "\n",
        "# üßæ Evaluation\n",
        "print(\"‚úÖ Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"üéØ Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
        "print(\"üéØ Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
        "print(\"üéØ F1 Score:\", f1_score(y_test, y_pred, average='weighted'))\n",
        "print(\"\\nüìã Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nüßÆ Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# üíæ Save Everything\n",
        "model.save(lstm_final_path)\n",
        "with open(xgb_model_path, 'wb') as f:\n",
        "    pickle.dump(xgb, f)\n",
        "with open(tokenizer_path, 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "pd.DataFrame({'Actual': y_test, 'Predicted': y_pred}).to_csv(xgb_pred_path, index=False)\n",
        "\n",
        "# üìà Accuracy & Loss Plots from Log\n",
        "if os.path.exists(csv_log_path):\n",
        "    df_log = pd.read_csv(csv_log_path)\n",
        "\n",
        "    if 'accuracy' in df_log.columns and 'val_accuracy' in df_log.columns:\n",
        "        plt.figure()\n",
        "        plt.plot(df_log['accuracy'], label='Training Accuracy')\n",
        "        plt.plot(df_log['val_accuracy'], label='Validation Accuracy')\n",
        "        plt.title('Training vs Validation Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(plot_acc_path)\n",
        "        plt.close()\n",
        "        print(f\"‚úÖ Accuracy plot saved: {plot_acc_path}\")\n",
        "\n",
        "    if 'loss' in df_log.columns and 'val_loss' in df_log.columns:\n",
        "        plt.figure()\n",
        "        plt.plot(df_log['loss'], label='Training Loss')\n",
        "        plt.plot(df_log['val_loss'], label='Validation Loss')\n",
        "        plt.title('Training vs Validation Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(plot_loss_path)\n",
        "        plt.close()\n",
        "        print(f\"‚úÖ Loss plot saved: {plot_loss_path}\")\n",
        "\n",
        "# üìä Confusion Matrix with Class Labels\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "class_labels = ['Legitimate', 'Phishing']\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, ax=ax, values_format='d')\n",
        "plt.title(\"Confusion Matrix with Class Names\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(conf_matrix_path)\n",
        "plt.close()\n",
        "print(f\"‚úÖ Confusion matrix saved: {conf_matrix_path}\")\n",
        "\n",
        "# üìã Classification Report CSV\n",
        "report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
        "report_df = pd.DataFrame(report_dict).transpose()\n",
        "report_df.to_csv(report_csv_path)\n",
        "print(f\"‚úÖ Classification report saved: {report_csv_path}\")\n",
        "\n",
        "# üìà XGBoost Feature Importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_importance(xgb)\n",
        "plt.title(\"XGBoost Feature Importance\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(feature_importance_path)\n",
        "plt.close()\n",
        "print(f\"‚úÖ Feature importance plot saved: {feature_importance_path}\")\n",
        "\n",
        "# üóúÔ∏è Zip Everything\n",
        "files_to_zip = [\n",
        "    checkpoint_path,\n",
        "    lstm_final_path,\n",
        "    xgb_model_path,\n",
        "    tokenizer_path,\n",
        "    xgb_pred_path,\n",
        "    csv_log_path,\n",
        "    plot_acc_path,\n",
        "    plot_loss_path,\n",
        "    conf_matrix_path,\n",
        "    feature_importance_path,\n",
        "    report_csv_path,\n",
        "    f\"{base_path}/label_encoder.pkl\"  # Only if it exists\n",
        "]\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "    for file_path in files_to_zip:\n",
        "        if os.path.exists(file_path):\n",
        "            zipf.write(file_path, os.path.basename(file_path))\n",
        "            print(f\"üì¶ Added to ZIP: {os.path.basename(file_path)}\")\n",
        "        else:\n",
        "            print(f\" Missing file (not zipped): {os.path.basename(file_path)}\")\n",
        "\n",
        "print(f\"\\n‚úÖ All artifacts zipped to: {zip_path}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "2yZPqoBvZzg2",
        "outputId": "96b2b847-c7cc-46d2-8ae5-bdbfae332f39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Confusion matrix saved: /content/drive/My Drive/email_datasets/confusion_matrix_named.png\n",
            "‚úÖ Classification report saved: /content/drive/My Drive/email_datasets/classification_report.csv\n",
            "‚úÖ Feature importance plot saved: /content/drive/My Drive/email_datasets/xgb_feature_importance.png\n",
            "üì¶ Added to ZIP: lstm_checkpoint.keras\n",
            "üì¶ Added to ZIP: lstm_final_model.keras\n",
            "üì¶ Added to ZIP: lstm_xgb_model.pkl\n",
            "üì¶ Added to ZIP: text_tokenizer.pkl\n",
            "‚ùå Missing file (not zipped): label_encoder.pkl\n",
            "üì¶ Added to ZIP: xgb_predictions.csv\n",
            "‚ùå Missing file (not zipped): lstm_training_log.csv\n",
            "‚ùå Missing file (not zipped): training_accuracy.png\n",
            "‚ùå Missing file (not zipped): training_loss.png\n",
            "üì¶ Added to ZIP: confusion_matrix_named.png\n",
            "üì¶ Added to ZIP: xgb_feature_importance.png\n",
            "üì¶ Added to ZIP: classification_report.csv\n",
            "\n",
            "‚úÖ All artifacts zipped to: /content/drive/My Drive/email_datasets/hybrid_model_export.zip\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Imports\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        ")\n",
        "from xgboost import plot_importance\n",
        "\n",
        "# Paths\n",
        "base_path = \"/content/drive/My Drive/email_datasets\"\n",
        "csv_log_path = f\"{base_path}/lstm_training_log.csv\"\n",
        "plot_acc_path = f\"{base_path}/training_accuracy.png\"\n",
        "plot_loss_path = f\"{base_path}/training_loss.png\"\n",
        "conf_matrix_path = f\"{base_path}/confusion_matrix_named.png\"\n",
        "feature_importance_path = f\"{base_path}/xgb_feature_importance.png\"\n",
        "report_csv_path = f\"{base_path}/classification_report.csv\"\n",
        "zip_path = f\"{base_path}/hybrid_model_export.zip\"\n",
        "\n",
        "# üîÅ Dummy placeholders (replace these with your real predictions and labels if not already in scope)\n",
        "# These must be in scope before running:\n",
        "# y_test, y_pred, xgb\n",
        "\n",
        "# üìà Accuracy Plot\n",
        "if os.path.exists(csv_log_path):\n",
        "    df_log = pd.read_csv(csv_log_path)\n",
        "\n",
        "    if 'accuracy' in df_log.columns and 'val_accuracy' in df_log.columns:\n",
        "        plt.figure()\n",
        "        plt.plot(df_log['accuracy'], label='Training Accuracy')\n",
        "        plt.plot(df_log['val_accuracy'], label='Validation Accuracy')\n",
        "        plt.title('Training vs Validation Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(plot_acc_path)\n",
        "        plt.close()\n",
        "        print(f\"Accuracy plot saved: {plot_acc_path}\")\n",
        "\n",
        "    if 'loss' in df_log.columns and 'val_loss' in df_log.columns:\n",
        "        plt.figure()\n",
        "        plt.plot(df_log['loss'], label='Training Loss')\n",
        "        plt.plot(df_log['val_loss'], label='Validation Loss')\n",
        "        plt.title('Training vs Validation Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(plot_loss_path)\n",
        "        plt.close()\n",
        "        print(f\"‚úÖ Loss plot saved: {plot_loss_path}\")\n",
        "\n",
        "# Confusion Matrix with Class Labels\n",
        "if 'y_test' in locals() and 'y_pred' in locals():\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    class_labels = ['Legitimate', 'Phishing']\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    disp.plot(cmap=plt.cm.Blues, ax=ax, values_format='d')\n",
        "    plt.title(\"Confusion Matrix with Class Names\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(conf_matrix_path)\n",
        "    plt.close()\n",
        "    print(f\"‚úÖ Confusion matrix saved: {conf_matrix_path}\")\n",
        "\n",
        "    # Classification Report CSV\n",
        "    report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
        "    report_df = pd.DataFrame(report_dict).transpose()\n",
        "    report_df.to_csv(report_csv_path)\n",
        "    print(f\"‚úÖ Classification report saved: {report_csv_path}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Skipping confusion matrix and report (missing y_test or y_pred)\")\n",
        "\n",
        "# XGBoost Feature Importance\n",
        "if 'xgb' in locals():\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plot_importance(xgb)\n",
        "    plt.title(\"XGBoost Feature Importance\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(feature_importance_path)\n",
        "    plt.close()\n",
        "    print(f\"‚úÖ Feature importance plot saved: {feature_importance_path}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Skipping feature importance (missing xgb model)\")\n",
        "\n",
        "# Zip Everything\n",
        "files_to_zip = [\n",
        "    f\"{base_path}/lstm_checkpoint.keras\",\n",
        "    f\"{base_path}/lstm_final_model.keras\",\n",
        "    f\"{base_path}/lstm_xgb_model.pkl\",\n",
        "    f\"{base_path}/text_tokenizer.pkl\",\n",
        "    f\"{base_path}/label_encoder.pkl\",\n",
        "    f\"{base_path}/xgb_predictions.csv\",\n",
        "    csv_log_path,\n",
        "    plot_acc_path,\n",
        "    plot_loss_path,\n",
        "    conf_matrix_path,\n",
        "    feature_importance_path,\n",
        "    report_csv_path\n",
        "]\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "    for file_path in files_to_zip:\n",
        "        if os.path.exists(file_path):\n",
        "            zipf.write(file_path, os.path.basename(file_path))\n",
        "            print(f\"Added to ZIP: {os.path.basename(file_path)}\")\n",
        "        else:\n",
        "            print(f\" Missing file (not zipped): {os.path.basename(file_path)}\")\n",
        "\n",
        "print(f\"\\n‚úÖ All artifacts zipped to: {zip_path}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}